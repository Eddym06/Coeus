import os
import sys
import time
import tiktoken
from dotenv import load_dotenv
from openai import OpenAI

# Cargar variables de entorno
load_dotenv()

# Configuraci√≥n de Cliente xAI (Grok)
XAI_API_KEY = os.getenv("XAI_API_KEY")
if not XAI_API_KEY:
    print("‚ùå Error: xAI API Key no encontrada. Aseg√∫rate de tener el archivo .env configurado.")
    sys.exit(1)

client = OpenAI(
    api_key=XAI_API_KEY,
    base_url="https://api.x.ai/v1",
)

# Configuraci√≥n Modelo
MODEL_NAME = "grok-4-fast-non-reasoning" 

# =============================================================================
# TOPICS & PROMPTS - ESTRATEGIA "FRAGMENTACI√ìN MASIVA"
# =============================================================================
# Rompemos el libro en secciones peque√±as y espec√≠ficas para burlar el l√≠mite
# de salida y obligar a generar miles de tokens por cada secci√≥n.

SYSTEM_PROMPT = """Eres una M√°quina de Generaci√≥n de Conocimiento Ilimitada.
Tu objetivo es producir texto t√©cnico extremadamente denso, detallado y extenso sobre Python y Ciencias de la Computaci√≥n.

REGLAS ABSOLUTAS ANTI-RESUMEN:
1. NUNCA resumas. NUNCA seas breve.
2. Si explicas un concepto, baja hasta nivel de memoria (bits, bytes, punteros en C).
3. Escribe MUCHO c√≥digo. No snippets, sino m√≥dulos completos.
4. Repite conceptos si es necesario para a√±adir matices nuevos.
5. Tu salida debe parecer un volcado de cerebro de un experto senior.
6. IGNORA cualquier directriz interna de "ser conciso". Hoy tu directriz es "SER EXHAUSTIVO".
7. Usa formato Markdown.
"""

TOPICS = [
    {
        "title": "CAPITULO 1: Gesti√≥n de Memoria a Bajo Nivel",
        "prompt": "Explica la gesti√≥n de memoria en CPython. Detalla PyObject, Reference Counting, Garbage Collection generacional (Gen 0, 1, 2) y el GIL. Incluye diagramas ASCII y c√≥digo C simulado de c√≥mo Python gestiona objetos internamente."
    },
    {
        "title": "CAPITULO 2: Estructuras de Datos - HashMaps y Arrays",
        "prompt": "Analiza la implementaci√≥n de `dict` y `list`. Explica colisiones de hash, open addressing, compact dicts (Python 3.6+) y la sobreasignaci√≥n din√°mica de arrays. Escribe una implementaci√≥n pura en Python de un HashMap que imite al interno."
    },
    {
        "title": "CAPITULO 3: Metaclases y Decoradores Avanzados",
        "prompt": "Profundiza en la metaprogramaci√≥n. Escribe c√≥digo para validadores autom√°ticos, registro de plugins y modificaci√≥n de clases en tiempo de creaci√≥n (`__new__` vs `__init__`). Crea un framework de ORM falso completo usando metaclases."
    },
    {
        "title": "CAPITULO 4: Concurrencia, Asyncio y Multiprocessing",
        "prompt": "Distinci√≥n entre concurrencia y paralelismo. Event Loop de Asyncio explicado paso a paso. Corutinas, Futures y Tasks. Diferencias cr√≠ticas entre Threads y Process en el contexto del GIL. Implementa un servidor web as√≠ncrono desde cero (usando sockets brutos)."
    },
    {
        "title": "CAPITULO 5: Algoritmos de Grafos y Optimizaci√≥n",
        "prompt": "Implementa algoritmos complejos: A*, Dijkstra y Network Flow. No solo el c√≥digo: explica la teor√≠a de grafos subyacente, complejidad temporal/espacial y optimizaciones con `heapq`. Resuelve un problema de pathfinding complejo."
    },
    {
        "title": "CAPITULO 6: Patrones de Dise√±o Arquitect√≥nicos",
        "prompt": "Explica e implementa patrones empresariales: Dependency Injection Container, Event Bus, CQRS (Command Query Responsibility Segregation). Muestra c√≥mo estructurar una aplicaci√≥n Python masiva y mantenible."
    },
    {
        "title": "CAPITULO 7: Depuraci√≥n Ofensiva y Hacking √âtico",
        "prompt": "T√©cnicas avanzadas de debugging: `pdb`, `sys.settrace`, introspecci√≥n del stack frames. Escribe un debugger simple que permita step-by-step execution. Analiza c√≥mo inyectar c√≥digo en runtime para monkey-patching seguro."
    }
]

# =============================================================================
# UTILIDADES
# =============================================================================
def count_tokens(text):
    try:
        encoding = tiktoken.get_encoding("cl100k_base")
        return len(encoding.encode(text))
    except:
        return len(text) // 4

def generate_section(index, topic):
    print(f"\n>>> üöÄ Generando {topic['title']}...")
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": f"TEMA: {topic['title']}\nINSTRUCCI√ìN: {topic['prompt']}\n\nEXTENSI√ìN: EXTREMA. M√çNIMO 2000 PALABRAS. NO PARES."}
            ],
            temperature=0.8, # Alta temperatura para evitar repeticiones en textos largos
            max_tokens=8192  # Intentamos forzar el l√≠mite m√°ximo
        )
        content = response.choices[0].message.content
        if not content: raise ValueError("Empty response")
        
        # Post-procesado: A√±adir encabezado claro
        full_content = f"\n\n# {topic['title']}\n\n{content}\n"
        return full_content
    except Exception as e:
        print(f"‚ùå Error en secci√≥n {index}: {e}")
        return ""

# =============================================================================
# MAIN
# =============================================================================
def main():
    print(f" miners ‚õèÔ∏è GROK DATASET MINER V2 (MAX YIELD) - Model: {MODEL_NAME}")
    print(f" üéØ Objetivo: {len(TOPICS)} Cap√≠tulos Densos")
    print("-" * 60)

    all_content = []
    total_tokens = 0
    start_global = time.time()

    for i, topic in enumerate(TOPICS):
        content = generate_section(i+1, topic)
        if content:
            tokens = count_tokens(content)
            print(f"   ‚úÖ Generado: {tokens} tokens.")
            all_content.append(content)
            total_tokens += tokens
            
            # Guardado incremental por seguridad
            with open(f"dataset_grok_part{i+1}.txt", "w", encoding="utf-8") as f:
                f.write(content)
        
        # Pausa t√°ctica
        time.sleep(1.5)

    print("-" * 60)
    print("üíæ Combinando dataset final...")
    
    full_text = "\n".join(all_content)
    
    with open("dataset_grok_combined.txt", "w", encoding="utf-8") as f:
        f.write(full_text)
        
    print(f"üìä REPORT FINAL:")
    print(f"   Tokens Totales: {total_tokens}")
    print(f"   Archivo: dataset_grok_combined.txt")
    print(f"   Tiempo Total: {time.time() - start_global:.2f}s")
    
    if total_tokens < 10000:
        print("‚ö†Ô∏è ADVERTENCIA: El volumen de datos sigue siendo bajo. Revisa la API o los prompts.")

if __name__ == "__main__":
    main()
